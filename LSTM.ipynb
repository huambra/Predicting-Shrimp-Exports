{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFM\n",
    "# Modelo LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REALIZADO POR: JOSE XAVIER MONAR MEJIA <br>\n",
    "FECHA: ENERO/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preparación del Entorno para el Modelo LSTM**\n",
    "\n",
    "En este bloque, importaremos todas las librerías necesarias para implementar un modelo LSTM. Estas incluyen herramientas para la manipulación de datos, visualización, preprocesamiento, construcción del modelo, entrenamiento y evaluación. A continuación, detallamos el propósito de cada librería:\n",
    "\n",
    "- **Manipulación de datos**:\n",
    "  - `pandas`: Para cargar y procesar datos estructurados.\n",
    "  - `numpy`: Para operaciones matemáticas y manejo de arrays.\n",
    "\n",
    "- **Visualización de datos**:\n",
    "  - `matplotlib`: Para generar gráficos básicos.\n",
    "  - `seaborn`: Para gráficos más estilizados y análisis exploratorios.\n",
    "\n",
    "- **Preprocesamiento y escalado**:\n",
    "  - `sklearn.preprocessing.MinMaxScaler`: Para normalizar los datos entre 0 y 1.\n",
    "\n",
    "- **Construcción y entrenamiento del modelo**:\n",
    "  - `tensorflow.keras`: Para construir, entrenar y evaluar el modelo LSTM.\n",
    "    - `Sequential`: Para estructurar el modelo en capas.\n",
    "    - `LSTM`: Para añadir capas LSTM al modelo.\n",
    "    - `Dense`: Para añadir capas completamente conectadas.\n",
    "    - `Dropout`: Para evitar el sobreajuste.\n",
    "\n",
    "- **Evaluación del modelo**:\n",
    "  - `sklearn.metrics`: Para calcular métricas de rendimiento como MAE, MSE y RMSE.\n",
    "\n",
    "- **Configuración del entorno**:\n",
    "  - `os`: Para gestionar rutas de archivos si es necesario.\n",
    "  - `warnings`: Para suprimir advertencias innecesarias.\n",
    "\n",
    "A continuación, realizamos las importaciones correspondientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow instalado correctamente, versión: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"TensorFlow instalado correctamente, versión: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd  # Manejo de estructuras de datos como DataFrames\n",
    "import numpy as np   # Operaciones matemáticas y arrays\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt  # Gráficos básicos\n",
    "import seaborn as sns  # Visualizaciones avanzadas\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "from sklearn.preprocessing import MinMaxScaler  # Normalización de datos\n",
    "\n",
    "# Construcción y entrenamiento del modelo LSTM\n",
    "from tensorflow.keras.models import Sequential  # Para crear el modelo\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout  # Capas LSTM y Dense\n",
    "from tensorflow.keras.optimizers import Adam  # Optimizador\n",
    "\n",
    "# Evaluación del modelo\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Configuración del entorno\n",
    "import os  # Manejo de rutas\n",
    "import warnings  # Supresión de advertencias\n",
    "warnings.filterwarnings('ignore')  # Ignorar advertencias innecesarias\n",
    "\n",
    "# Configuración de estilo para los gráficos\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Confirmación de que las librerías han sido cargadas correctamente\n",
    "print(\"Librerías importadas con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carga del Dataset**\n",
    "\n",
    "En este bloque, cargaremos el dataset ubicado en la siguiente URL:\n",
    "`https://github.com/huambra/Predicting-Shrimp-Exports/raw/refs/heads/main/Exports%20por%20Mercado.xlsx`.\n",
    "\n",
    "## Pasos:\n",
    "1. Importaremos la librería `pandas`, que nos permite leer archivos Excel.\n",
    "2. Usaremos la función `read_excel` para cargar el archivo.\n",
    "3. Mostraremos las primeras filas del dataset para asegurarnos de que se cargó correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "        Date  China   USA    UE\n",
      "0 2012-12-01   19.0   291    75\n",
      "1 2013-01-01  740.0  4119  4241\n",
      "2 2013-02-01  380.0  5844  5407\n",
      "3 2013-03-01  459.0  6929  7510\n",
      "4 2013-04-01  403.0  7266  7830\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141 entries, 0 to 140\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    141 non-null    datetime64[ns]\n",
      " 1   China   141 non-null    float64       \n",
      " 2   USA     141 non-null    int64         \n",
      " 3   UE      141 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2)\n",
      "memory usage: 4.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "file_path = \"https://github.com/huambra/Predicting-Shrimp-Exports/raw/refs/heads/main/Exports%20por%20Mercado.xlsx\"\n",
    "\n",
    "# Cargamos el dataset\n",
    "try:\n",
    "    data = pd.read_excel(file_path, sheet_name=\"Unpivot\")\n",
    "    # Mostramos las primeras filas del dataset\n",
    "    print(\"Primeras filas del dataset:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Verificamos la estructura del dataset\n",
    "    print(\"\\nInformación del dataset:\")\n",
    "    print(data.info())\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el dataset: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
